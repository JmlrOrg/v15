{
    "abstract": "In this paper we present a general treatment of the preference aggregation problem, in which multiple preferences over objects must be combined into a single consensus ranking. We consider two instances of this problem: unsupervised aggregation where no information about a target ranking is available, and supervised aggregation where ground truth preferences are provided. For each problem class we develop novel learning methods that are applicable to a wide range of preference types. (The code for all models introduced in this paper is available at <a href=\"htt p://www.cs.toronto.edu/~mvolkovs\">www.cs.toronto.edu/~mvolkovs</a>.)  Specifically, for unsupervised aggregation we introduce the Multinomial Preference model (MPM) which uses a multinomial generative process to model the observed preferences. For the supervised problem we develop a supervised extension for MPM and then propose two fully supervised models. The first model employs SVD factorization to derive effective item features, transforming the aggregation problems into a learning-to-rank one. The second model aims to eliminate the costly SVD factorization and instantiates a probabilistic CRF framework, deriving unary and pairwise potentials directly from the observed preferences. Using a probabilistic framework allows us to directly optimize the expectation of any target metric, such as NDCG or ERR. All the proposed models operate on pairwise preferences and can thus be applied to a wide range of preference types. We empirically validate the models on rank aggregation and collaborative filtering data sets and demonstrate superior empirical accuracy.",
    "authors": [
        "Maksims N. Volkovs",
        "Richard S. Zemel"
    ],
    "id": "volkovs14a",
    "issue": 33,
    "pages": [
        1135,
        1176
    ],
    "title": "New Learning Methods for Supervised and Unsupervised Preference Aggregation",
    "volume": 15,
    "year": 2014
}